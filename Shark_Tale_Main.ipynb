{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep this here pls\n",
    "!pip install xlrd \n",
    "#!pip install country_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#define path to xls\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "df = pd.read_excel(url)\n",
    "df  # 6992 rows × 23 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]\n",
    "df.shape[1]\n",
    "\n",
    "print(\"Number of Rows: \", df.shape[0])\n",
    "print(\"Number of Columns: \", df.shape[1])\n",
    "\n",
    "df.columns\n",
    "\n",
    "# Issues w/ og file –> extra 8 columns on VSC? to preserve NaN\n",
    "# Date, Year, Type, Country, State, Location, Activity, Name, Sex, Age, Injury, Fatal Y/N, Time, Specie, Source\n",
    "# check search tool between uppercase and lowercase e.g. Australia / AUSTRALIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns= {\n",
    "    'Fatal Y/N': 'Fatal',\n",
    "    'Species ': 'Species',\n",
    "    'pdf': 'PDF', \n",
    "    'href formula': 'Href_formula', \n",
    "    'href': 'Href',\n",
    "    'Case Number': 'Case_Number', \n",
    "    'Case Number.1': 'Case_Number_1',\n",
    "    'original order': 'Original_Order', \n",
    "    'Unnamed: 21': 'Unnamed_21', \n",
    "    'Unnamed: 22': 'Unnamed_22'\n",
    "}, inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() # Reviewing here the unique values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am trying to identify the number of unique values for each column and determine which columns appear to be categorical. \n",
    "unique_counts = df.nunique() # Identify the number of unique values for each column\n",
    "print(\"\\nUnique value counts per column: \")\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values in each column \n",
    "df.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() # Reviewing here the number of unique values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df.columns: \n",
    "#    if df[col].dtype == object: \n",
    "#        print(col)\n",
    "#        print(df[col].nunique())\n",
    "#        print(df[col].unique())\n",
    "#    else: \n",
    "#        print(col)\n",
    "#        print(df[col].nunique())\n",
    "#        print(df[col].min(), df[col].max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for the Column 'Type' \n",
    "\n",
    "#Reviewing how many were provoked and unprovoked \n",
    "print(df[\"Type\"].unique())\n",
    "df[\"Type\"] = df[\"Type\"].replace({\n",
    "    \" Provoked\": \"Provoked\", \n",
    "    \"Unconfirmed\": \"Unverified\",\n",
    "    \"?\" : \"Unverified\",\n",
    "    \"Questionable\": \"Unverified\"\n",
    "})\n",
    "\n",
    "df_nan = df[df[\"Type\"].isna()]\n",
    "df_nan\n",
    "\n",
    "df[\"Type\"] = df[\"Type\"].isnull().sum\n",
    "\n",
    "# What is the meaning in here as \"Provoked\"?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of null values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for the Column Gender\n",
    "df[\"Sex\"] = df[\"Sex\"].replace({\" M\": \"M\", \"M \": \"M\", \"M x 2\": \"M\", \" nan\": \"Unknown\", \"lli\": \"Unknown\", \"N\": \"M\", \".\": \"Unknown\", \" nan\":\"Unknown\"})\n",
    "df[\"Sex\"] = df[\"Sex\"].fillna(\"Unknown\")\n",
    "df.Sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleanining for the Column Species\n",
    "df[\"Species\"] = df[\"Species\"].str.extract(r'([A-Za-z\\s-]+)').fillna(\"Unknown\") # Cleaning here the unnecessary details\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for the column 'Country', I've tried to use regex \n",
    "df[\"Country\"] = df[\"Country\"].str.strip().str.title()\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(r\"[^a-zA-Z\\s]\", \"\", regex=True)\n",
    "#df[\"Country\"] = df[\"Country\"].map(lambda x: x.upper())\n",
    "df[\"Country\"] = df[\"Country\"].fillna(\"Unknown\")\n",
    "print(df[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning for location\n",
    "df[\"Location\"] = df[\"Location\"].astype(str)\n",
    "df[\"Location\"] = df[\"Location\"].map(lambda x:x.upper())\n",
    "df[\"Location\"] = df[\"Location\"].fillna(\"Unknown\")\n",
    "df[\"Location\"] = df[\"Location\"].str.strip()\n",
    "df[\"Location\"] = df[\"Location\"].replace({\n",
    "    \"NAN\": \"Unknown\",\n",
    "     \"nan\": \"Unknown\",\n",
    "      \"Nan\": \"Unknown\", \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for the Column 'State'\n",
    "#df[\"State\"] = df[\"State\"].\n",
    "df[\"State\"] = df[\"State\"].fillna(\"Unknown\")\n",
    "df[\"State\"] = df[\"State\"].astype(str)\n",
    "df[\"State\"] = df[\"State\"].str.strip()\n",
    "df[\"State\"] = df[\"State\"].replace({\n",
    "    \"NAN\": \"Unknown\",\n",
    "    \"nan\": \"Unknown\",\n",
    "    \"Nan\": \"Unknown\", \n",
    "    \" \": \"Unknown\",\n",
    "    \"  \": \"Unknown\"\n",
    "})\n",
    "print(df[\"State\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for the Column Activity \n",
    "df[\"Activity\"] = df[\"Activity\"].fillna(\"Unknown\")\n",
    "df[\"Activity\"] = df[\"Activity\"].astype(str)\n",
    "df[\"Activity\"] = df[\"Activity\"].str.strip()\n",
    "df[\"Activity\"] = df[\"Activity\"].replace({\n",
    "    \"NAN\": \"Unknown\",\n",
    "     \"nan\": \"Unknown\",\n",
    "      \"Nan\": \"Unknown\",\n",
    "})\n",
    "# Needs more cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for the Column 'Name' \n",
    "df[\"Activity\"] = df[\"Activity\"].fillna(\"Unknown\")\n",
    "df[\"Activity\"] = df[\"Activity\"].astype(str)\n",
    "df[\"Activity\"] = df[\"Activity\"].str.strip()\n",
    "df[\"Activity\"] = df[\"Activity\"].replace({\n",
    "    \"NAN\": \"Unknown\",\n",
    "     \"nan\": \"Unknown\",\n",
    "      \"Nan\": \"Unknown\",\n",
    "})\n",
    "# Needs to be furthered cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for the Column Age\n",
    "# df[\"Age\"] = df[\"Age\"].astype()\n",
    "# df[\"Age\"] = df[\"Age\"]\n",
    "# df[\"Age\"] = df[\"Age\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning for The Column Fatal\n",
    "df[\"Fatal\"] = df[\"Fatal\"].fillna(\"Unknown\")\n",
    "df[\"Fatal\"] = df[\"Fatal\"].astype(str)\n",
    "df[\"Fatal\"] = df[\"Fatal\"].replace({\n",
    "    \"Nan\": \"Unknown\",\n",
    "    \" N\": \"N\",\n",
    "    \"UNKNOWN\": \"Unknown\",\n",
    "    \"F\": \"Unknown\",\\\n",
    "    \"M\": \"N\",\n",
    "    \"n\": \"N\",\n",
    "    \"Nq\": \"N\",\n",
    "     2017: \"Unknown\",\n",
    "     \"Y x 2\": \"Y\",\n",
    "     \"y\": \"Y\",\n",
    "     \"N   \": \"N\",\n",
    "})\n",
    "#df[\"Fatal\"] = df[\"Fatal\"]\n",
    "#df[\"Fatal\"] = df[\"Fatal\"]\n",
    "#df[\"Fatal\"] = df[\"Fatal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fatal'].value_counts(dropna=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
